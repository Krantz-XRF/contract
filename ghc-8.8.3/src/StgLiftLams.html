<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<!-- Generated by HsColour, http://code.haskell.org/~malcolm/hscolour/ -->
<title>simplStg/StgLiftLams.hs</title>
<link type='text/css' rel='stylesheet' href='hscolour.css' />
</head>
<body>
<pre><a name="line-1"></a><span class='hs-comment'>-- | Implements a selective lambda lifter, running late in the optimisation</span>
<a name="line-2"></a><span class='hs-comment'>-- pipeline.</span>
<a name="line-3"></a><span class='hs-comment'>--</span>
<a name="line-4"></a><span class='hs-comment'>-- The transformation itself is implemented in "StgLiftLams.Transformation".</span>
<a name="line-5"></a><span class='hs-comment'>-- If you are interested in the cost model that is employed to decide whether</span>
<a name="line-6"></a><span class='hs-comment'>-- to lift a binding or not, look at "StgLiftLams.Analysis".</span>
<a name="line-7"></a><span class='hs-comment'>-- "StgLiftLams.LiftM" contains the transformation monad that hides away some</span>
<a name="line-8"></a><span class='hs-comment'>-- plumbing of the transformation.</span>
<a name="line-9"></a><span class='hs-keyword'>module</span> <span class='hs-conid'>StgLiftLams</span> <span class='hs-layout'>(</span>
<a name="line-10"></a>    <span class='hs-comment'>-- * Late lambda lifting in STG</span>
<a name="line-11"></a>    <span class='hs-comment'>-- $note</span>
<a name="line-12"></a>    <span class='hs-conid'>Transformation.stgLiftLams</span>
<a name="line-13"></a>  <span class='hs-layout'>)</span> <span class='hs-keyword'>where</span>
<a name="line-14"></a>
<a name="line-15"></a><span class='hs-keyword'>import</span> <span class='hs-keyword'>qualified</span> <span class='hs-conid'>StgLiftLams.Transformation</span> <span class='hs-keyword'>as</span> <span class='hs-conid'>Transformation</span>
<a name="line-16"></a>
<a name="line-17"></a><span class='hs-comment'>-- Note [Late lambda lifting in STG]</span>
<a name="line-18"></a><span class='hs-comment'>-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<a name="line-19"></a><span class='hs-comment'>-- $note</span>
<a name="line-20"></a><span class='hs-comment'>-- See also the &lt;https://ghc.haskell.org/trac/ghc/wiki/LateLamLift wiki page&gt;</span>
<a name="line-21"></a><span class='hs-comment'>-- and Trac #9476.</span>
<a name="line-22"></a><span class='hs-comment'>--</span>
<a name="line-23"></a><span class='hs-comment'>-- The basic idea behind lambda lifting is to turn locally defined functions</span>
<a name="line-24"></a><span class='hs-comment'>-- into top-level functions. Free variables are then passed as additional</span>
<a name="line-25"></a><span class='hs-comment'>-- arguments at *call sites* instead of having a closure allocated for them at</span>
<a name="line-26"></a><span class='hs-comment'>-- *definition site*. Example:</span>
<a name="line-27"></a><span class='hs-comment'>--</span>
<a name="line-28"></a><span class='hs-comment'>-- @</span>
<a name="line-29"></a><span class='hs-comment'>--    let x = ...; y = ... in</span>
<a name="line-30"></a><span class='hs-comment'>--    let f = {x y} \a -&gt; a + x + y in</span>
<a name="line-31"></a><span class='hs-comment'>--    let g = {f x} \b -&gt; f b + x in</span>
<a name="line-32"></a><span class='hs-comment'>--    g 5</span>
<a name="line-33"></a><span class='hs-comment'>-- @</span>
<a name="line-34"></a><span class='hs-comment'>--</span>
<a name="line-35"></a><span class='hs-comment'>-- Lambda lifting @f@ would</span>
<a name="line-36"></a><span class='hs-comment'>--</span>
<a name="line-37"></a><span class='hs-comment'>--   1. Turn @f@'s free variables into formal parameters</span>
<a name="line-38"></a><span class='hs-comment'>--   2. Update @f@'s call site within @g@ to @f x y b@</span>
<a name="line-39"></a><span class='hs-comment'>--   3. Update @g@'s closure: Add @y@ as an additional free variable, while</span>
<a name="line-40"></a><span class='hs-comment'>--      removing @f@, because @f@ no longer allocates and can be floated to</span>
<a name="line-41"></a><span class='hs-comment'>--      top-level.</span>
<a name="line-42"></a><span class='hs-comment'>--   4. Actually float the binding of @f@ to top-level, eliminating the @let@</span>
<a name="line-43"></a><span class='hs-comment'>--      in the process.</span>
<a name="line-44"></a><span class='hs-comment'>--</span>
<a name="line-45"></a><span class='hs-comment'>-- This results in the following program (with free var annotations):</span>
<a name="line-46"></a><span class='hs-comment'>--</span>
<a name="line-47"></a><span class='hs-comment'>-- @</span>
<a name="line-48"></a><span class='hs-comment'>--    f x y a = a + x + y;</span>
<a name="line-49"></a><span class='hs-comment'>--    let x = ...; y = ... in</span>
<a name="line-50"></a><span class='hs-comment'>--    let g = {x y} \b -&gt; f x y b + x in</span>
<a name="line-51"></a><span class='hs-comment'>--    g 5</span>
<a name="line-52"></a><span class='hs-comment'>-- @</span>
<a name="line-53"></a><span class='hs-comment'>--</span>
<a name="line-54"></a><span class='hs-comment'>-- This optimisation is all about lifting only when it is beneficial to do so.</span>
<a name="line-55"></a><span class='hs-comment'>-- The above seems like a worthwhile lift, judging from heap allocation:</span>
<a name="line-56"></a><span class='hs-comment'>-- We eliminate @f@'s closure, saving to allocate a closure with 2 words, while</span>
<a name="line-57"></a><span class='hs-comment'>-- not changing the size of @g@'s closure.</span>
<a name="line-58"></a><span class='hs-comment'>--</span>
<a name="line-59"></a><span class='hs-comment'>-- You can probably sense that there's some kind of cost model at play here.</span>
<a name="line-60"></a><span class='hs-comment'>-- And you are right! But we also employ a couple of other heuristics for the</span>
<a name="line-61"></a><span class='hs-comment'>-- lifting decision which are outlined in "StgLiftLams.Analysis#when".</span>
<a name="line-62"></a><span class='hs-comment'>--</span>
<a name="line-63"></a><span class='hs-comment'>-- The transformation is done in "StgLiftLams.Transformation", which calls out</span>
<a name="line-64"></a><span class='hs-comment'>-- to 'StgLiftLams.Analysis.goodToLift' for its lifting decision.</span>
<a name="line-65"></a><span class='hs-comment'>-- It relies on "StgLiftLams.LiftM", which abstracts some subtle STG invariants</span>
<a name="line-66"></a><span class='hs-comment'>-- into a monadic substrate.</span>
<a name="line-67"></a><span class='hs-comment'>--</span>
<a name="line-68"></a><span class='hs-comment'>-- Suffice to say: We trade heap allocation for stack allocation.</span>
<a name="line-69"></a><span class='hs-comment'>-- The additional arguments have to passed on the stack (or in registers,</span>
<a name="line-70"></a><span class='hs-comment'>-- depending on architecture) every time we call the function to save a single</span>
<a name="line-71"></a><span class='hs-comment'>-- heap allocation when entering the let binding. Nofib suggests a mean</span>
<a name="line-72"></a><span class='hs-comment'>-- improvement of about 1% for this pass, so it seems like a worthwhile thing to</span>
<a name="line-73"></a><span class='hs-comment'>-- do. Compile-times went up by 0.6%, so all in all a very modest change.</span>
<a name="line-74"></a><span class='hs-comment'>--</span>
<a name="line-75"></a><span class='hs-comment'>-- For a concrete example, look at @spectral/atom@. There's a call to 'zipWith'</span>
<a name="line-76"></a><span class='hs-comment'>-- that is ultimately compiled to something like this</span>
<a name="line-77"></a><span class='hs-comment'>-- (module desugaring/lowering to actual STG):</span>
<a name="line-78"></a><span class='hs-comment'>--</span>
<a name="line-79"></a><span class='hs-comment'>-- @</span>
<a name="line-80"></a><span class='hs-comment'>--    propagate dt = ...;</span>
<a name="line-81"></a><span class='hs-comment'>--    runExperiment ... =</span>
<a name="line-82"></a><span class='hs-comment'>--      let xs = ... in</span>
<a name="line-83"></a><span class='hs-comment'>--      let ys = ... in</span>
<a name="line-84"></a><span class='hs-comment'>--      let go = {dt go} \xs ys -&gt; case (xs, ys) of</span>
<a name="line-85"></a><span class='hs-comment'>--            ([], []) -&gt; []</span>
<a name="line-86"></a><span class='hs-comment'>--            (x:xs', y:ys') -&gt; propagate dt x y : go xs' ys'</span>
<a name="line-87"></a><span class='hs-comment'>--      in go xs ys</span>
<a name="line-88"></a><span class='hs-comment'>-- @</span>
<a name="line-89"></a><span class='hs-comment'>--</span>
<a name="line-90"></a><span class='hs-comment'>-- This will lambda lift @go@ to top-level, speeding up the resulting program</span>
<a name="line-91"></a><span class='hs-comment'>-- by roughly one percent:</span>
<a name="line-92"></a><span class='hs-comment'>--</span>
<a name="line-93"></a><span class='hs-comment'>-- @</span>
<a name="line-94"></a><span class='hs-comment'>--    propagate dt = ...;</span>
<a name="line-95"></a><span class='hs-comment'>--    go dt xs ys = case (xs, ys) of</span>
<a name="line-96"></a><span class='hs-comment'>--      ([], []) -&gt; []</span>
<a name="line-97"></a><span class='hs-comment'>--      (x:xs', y:ys') -&gt; propagate dt x y : go dt xs' ys'</span>
<a name="line-98"></a><span class='hs-comment'>--    runExperiment ... =</span>
<a name="line-99"></a><span class='hs-comment'>--      let xs = ... in</span>
<a name="line-100"></a><span class='hs-comment'>--      let ys = ... in</span>
<a name="line-101"></a><span class='hs-comment'>--      in go dt xs ys</span>
<a name="line-102"></a><span class='hs-comment'>-- @</span>
</pre></body>
</html>
